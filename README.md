# DPA-Chicago-VLIN ‚úíÔ∏è

Repositorio para la clase de Arquitectura de Producto de Datos, primavera 2021-ITAM

| Nombre | usuario git |
|-------|-----------------|
|Arenas Morales Nayeli | arenitss |
|Hern√°ndez Mart√≠nez Luz Aurora | LuzVerde23 |
|Santiago Castillejos Ita Andehui | sancas96 |
|S√°nchez Guti√©rrez Vianney | visagu55 |

# Summary de los datos: üìã

Datos:
- [**Chicago Food Inspections**](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5)

Al 15 de enero de 2021 a las 7:39 p.m.
  - N√∫mero de registros: 215,067
  - N√∫mero de columnas: 17
  - Qu√© variables son, qu√© informaci√≥n tiene:

    - **Inspection ID**: Identificador consecutivo. Tipo num√©rico.
    - **DBA Name**: Acr√≥nimo de 'Doing business as', que es el nombre legal del establecimiento. Tipo texto.
    - **AKA Name**: Acr√≥nimo de 'Also known as' el nombre por el que es conocido el establecimiento. Tipo texto.
    - **License #**: N√∫mero de licencia asignada por el 'Department of Business Affairs and Consumer Protection'. Tipo num√©rico.
    - **Facility Type**: Tipo de servicio seg√∫n su descripci√≥n: bakery, banquet hall, candy store, caterer, coffee shop, day care center (for ages less than 2), day care center (for ages 2 ‚Äì 6), day care center (combo, for ages less than 2 and 2 ‚Äì 6 combined), gas station, Golden Diner, grocery store, hospital, long term care center(nursing home), liquor store, mobile food dispenser, restaurant, paleteria, school, shelter, tavern, social club, wholesaler, or Wrigley Field Rooftop. Tipo texto.
    - **Risk**: Cada establecimiento se categoriza seg√∫n el tipo de riesgo a la salud, esto es 1 (el m√°s alto) a 3 (el m√°s bajo). Tipo texto.
    - **Address**: Direcci√≥n para facilitar su ubicaci√≥n. Tipo texto.
    - **City**: Ciudad. Tipo texto.
    - **State**: Estado. Tipo texto.
    - **Zip**: C√≥digo postal. Tipo num√©rico.
    - **Inspection Date**: Describe la fecha en que la inspecci√≥n ocurri√≥, un establecimiento puede tener m√∫ltiples inspecciones. Tipo de fecha y hora.
    - **Inspection Type**: Las inspecciones se pueden describir como sigue:
        * canvass: el tipo m√°s com√∫n de inspecci√≥n que se ejecuta con una frecuencia relativa al riesgo del establecimiento.
        * consultation: cuando la inspecci√≥n se realiza a petici√≥n del due√±o previo a la apertura del establecimiento.
        * complaint: cuando la inspecci√≥n se realiza en respuesta a una queja en contra del establecimiento.
        * license: cuando la inspecci√≥n se realiza como un requerimiento para que el establecimiento pueda recibir su licencia para operar.
        * suspect food poisoning: inspecci√≥n que se realiza en respuesta a una o m√°s personas que indican haberse enfermado como resultado de haber comido en el establecimiento.
        * task-force inspection: cuando la inspecci√≥n de un bar o taberna se ejecuta. Tipo texto.

      La re-inspecci√≥n puede ocurrir para todos los tipos de inspecciones y se nombrar√≠an de la misma manera.
    - **Results**: Muestra el resultado de la inspecci√≥n bajo las siguientes categor√≠as: puede aprobarse, aprobarse con condiciones o fallar. Se encontr√≥ que "pasar" no ten√≠a violaciones cr√≠ticas o graves (violaci√≥n n√∫mero 1-14 y 15-29, respectivamente).Las categorias pueden ser: 'pass', 'pass with conditions' y 'fail'.  Tipo texto.
    - **Violations**: Un establecimiento puede recibir uno o m√°s de 45 (1-44 y 70) infracciones distintas a la norma. Adem√°s se enuncia el requisito que el establecimiento debe cumplir para NO recibir una infracci√≥n, seguido de una descripci√≥n espec√≠fica de los hallazgos que causaron la violaci√≥n. Tipo texto.
    - **Latitude**: Latitud del establecimiento. Tipo num√©rico.
    - **Longitude**: longitud del establecimiento. Tipo num√©rico.
    - **Location**: la latitud y longitud del establecimiento. Tipo localizaci√≥n.

  - La pregunta anal√≠tica que queremos resolver es: ¬øEl establecimiento pasar√° o no la inspecci√≥n?
  - Frecuencia de actualizaci√≥n de los datos: Diaria, aunque para efectos del proyecto ser√° de manera semanal.


# Reproducibilidad y requerimientos. ‚öôÔ∏è

**Importante** Recordar que todo el proyecto debe ser ejecutado desde tu ambiente de trabajo seleccionado, ejecutando `pyenv activate <<tu_ambiente>>`

Para este proyecto utilizamos la versio≈Ñ **Python 3.7.4**
1. En la carpeta data, colocar el archivo `Food_Inspections.csv` que est√° disponible en este [**Drive**](https://drive.google.com/file/d/1Pyobds5_o_4wKHbZQTsmzfVd-NszjEQM/view?usp=sharing)
2. En tu ambiente virtual hay que instalar las librer√≠as del archivo requirements.txt : `pip install -r requirements.txt`
3. En la terminal debemos estar ubicados en la carpeta de este repositorio y ejecutar un `export PYTHONPATH=$PWD`
-----

# An√°lisis Exploratorio ‚å®Ô∏è
El notebook `Chicago_food_inspections.ipynb` con el an√°lisis exploratorio se encuentra en la carpeta `notebooks/eda/`.

# Ingesti√≥n y almacenamiento automatizado con Luigi üõ†Ô∏è

**Nota:** Para la correcta ejecuci√≥n de la ingesti√≥n y almacenamiento se actualiz√≥ el archivo `requirements.txt`.

1. Para la ejecuci√≥n de este checkpoint se asume que se tiene un archivo que se encuentra en la carpeta `conf/local/` con las credenciales de aws, este archivo deber√° ser llamado `credentials.yaml` con el siguiente esqueleto:

```
s3:
  aws_access_key_id : "xxxxxx"
  aws_secret_access_key : "xxxxxx"
food_inspections:
  api_token: "xxxxxxx"
chicago_database:
  user: "chicago_user"
  password: "chicago_pass"
  database: "chicago_db"
  host: "localhost"
  port: "5432"

```

Donde las llaves de `s3` son para interactuar de manera m√°s sencilla con el servicio de almacenamiento de archivos de `aws`.
El apartado de `food_inspections` contiene la llave `api_token` que es el token generado desde [**aqu√≠**](https://data.cityofchicago.org/login?return_to=%2Fprofile%2Fedit%2Fdeveloper_settings) que funcionar√° para hacer la ingesti√≥n de la API. Para m√°s informaci√≥n se puede consultar [**aqu√≠**](https://dev.socrata.com/foundry/data.cityofchicago.org/4ijn-s7e5).

2. De igual manera se asume que dentro de _aws_ se tenga levantado un bucket llamado `data-product-architecture-equipo8` con la siguiente estructura:
```
    ‚îú‚îÄ‚îÄ data-product-architecture-equipo8
    ‚îÇ   ‚îú‚îÄ‚îÄ ingesta    
```
3. Ejecutar `luigid` y en el navegador entrar a `http://localhost:8082/static/visualiser/index.html`

4. Para la ingesta, almacenamiento, limpieza e ingenier√≠a de caracter√≠sticas, ocuparemos como orquestador a [Luigi](https://luigi.readthedocs.io/en/stable/index.html). Para cada una de estas tareas los parametros necesarios pueden ser los siguientes:

    - **tipo_ingesta**: historica o consecutiva.
    - **fecha**: Fecha en la que se est√° haciendo la ingesta con respecto a inspection date.
    - **bucket**: nombre de tu bucket en `aws`.

Para poder correr los siguientes comandos, primero en tu entorno RDS debemos tener el schema metadata, para esto puedes ocupar los scripts que se encuentran en la carpeta sql: `create_metadata_tables.sql`.

La estructura desarrollada es la siguiente:

  Ingesta inicial: Con las credenciales que se dieron de alta para conectarnos a la API de _data.cityofchicago.org_, descargamos la base de datos disponible hasta la fecha. Este archivo se guardara con el nombre `historica-{fecha}.pkl`
```
PYTHONPATH=$PWD luigi --module src.pipeline.almacenamiento almacenar --tipo-ingesta historica --fecha 2021-01-21T00:00:00.00 --bucket data-product-architecture-equipo8
```    
  Ingesta consecutiva: Es la descarga de los datos posteriores a la ingesta inicial hasta la fecha solicitada. Este archivo se guardara con el nombre `consecutiva-{fecha}.pkl`
```
PYTHONPATH=$PWD luigi --module src.pipeline.almacenamiento almacenar --tipo-ingesta consecutiva --fecha 2021-03-17T00:00:00.00 --bucket data-product-architecture-equipo8
```
Cada uno de estos ejemplos almacena tambi√©n en un directorio la metadata de cada uno de los procesos -datos de los datos-

Limpieza de datos: Con la base de datos obtenida en las tareas de ingesti√≥n y almacenamiento, hacemos un proceso de limpieza donde:

  - Se eliminan los datos nulos de las variables `inspection_date`, `license_`, `latitude`, `longitude`,
  - Se eligen solo los establecimientos que est√°n en operaci√≥n,
  - Se eliminan los duplicados,
  - Se sustituyen los datos nulos restantes con cero.

Metadata de limpieza de datos: Guardamos la metadata generada por el proceso de limpieza.

```
#codigo limpieza y su metadata
```
Ingenier√≠a de caracter√≠sticas: Con los datos limpios, corremos el proceso de ingenier√≠a de caracter√≠sticas en donde:
  - Convertimos la variable de infracciones en columnas de tipo dummy,
  - Aplicamos label encoding (convertir a categor√≠as num√©ricas variables categ√≥ricas de tipo string),
  - Eliminamos las variables que no aportan informaci√≥n relevante al modelo.

Metadata de ingenier√≠a de caracter√≠sticas: Guardamos la metadata generada por el proceso de ingenier√≠a de caracter√≠sticas.

```
#codigo ingenier√≠a de caracter√≠sticas y su metadata
```

5. Revisa dentro de tu bucket de aws que la informaci√≥n est√© almacenada.

Al terminar este proceso verificamos el DAG en Luigi.

<img width="1020" alt="imagen" src="https://github.com/sancas96/DPA-Chicago-VLIN/blob/main/images/dag_luigi.png">


# Basti√≥n üìñ

Para tener acceso al Basti√≥n se requiere que el administrador le haya dado acceso al mismo y tener un usuario asignado y correr en su terminal lo siguiente:

    `ssh -i <<llave_privada>> <<usuario>>@ip_del_ec2`

**Nota:** El usuario lmillan ya fue asignado con la llave correspondiente.

---

**Figura 1**. Estructura b√°sica del proyecto.

```  
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ conf
‚îÇ   ‚îú‚îÄ‚îÄ base           <- Space for shared configurations like parameters
‚îÇ   ‚îî‚îÄ‚îÄ local          <- Space for local configurations, usually credentials
‚îú‚îÄ‚îÄ data               <- Space for data
‚îú‚îÄ‚îÄ docs               <- Space for Sphinx documentation
‚îú‚îÄ‚îÄ images             <- Space for images
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks.
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ results            <- Intermediate analysis as HTML, PDF, LaTeX, etc.
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file
‚îÇ
‚îú‚îÄ‚îÄ .gitignore         <- Avoids uploading data, credentials, outputs, system files etc
‚îÇ
‚îú‚îÄ‚îÄ infrastructure
‚îú‚îÄ‚îÄ sql
‚îú‚îÄ‚îÄ setup.py
‚îî‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils          <- Functions used across the project
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ etl            <- Scripts to transform data from raw to intermediate
    ‚îÇ
    ‚îÇ
    ‚îî‚îÄ‚îÄ pipeline       <- Scripts to data ingestion
```
